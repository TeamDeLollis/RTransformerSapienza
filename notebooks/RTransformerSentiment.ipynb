{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of RTransformerSentiment.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohRLKNtg4oq_",
        "colab_type": "code",
        "outputId": "8269a8f2-a83c-44ab-b56c-3246340673d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd /content/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YE7QnnBc46wE",
        "colab_type": "code",
        "outputId": "13f8b154-c546-4e61-fd2a-efd17d801171",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CkI4duJY480K",
        "colab_type": "code",
        "outputId": "eb8ecb75-3ebc-41e2-9521-de14d83a8b13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "!git clone https://TeamDeLollis:diag1234!@github.com/TeamDeLollis/RTransformerSapienza"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'RTransformerSapienza'...\n",
            "remote: Enumerating objects: 62, done.\u001b[K\n",
            "remote: Counting objects: 100% (62/62), done.\u001b[K\n",
            "remote: Compressing objects: 100% (62/62), done.\u001b[K\n",
            "remote: Total 42706 (delta 42), reused 1 (delta 0), pack-reused 42644\n",
            "Receiving objects: 100% (42706/42706), 372.42 MiB | 32.10 MiB/s, done.\n",
            "Resolving deltas: 100% (395/395), done.\n",
            "Checking out files: 100% (42485/42485), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tLqrYNDbCfQ",
        "colab_type": "code",
        "outputId": "09abf144-2fc4-4984-ffbc-98f7dd685ba0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd RTransformerSapienza"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/RTransformerSapienza\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMX6pEQwbDnq",
        "colab_type": "code",
        "outputId": "33646bc9-bfe7-4195-c173-154e6c36c652",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "source": [
        "!git pull"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "remote: Enumerating objects: 7, done.\u001b[K\n",
            "remote: Counting objects:  14% (1/7)\u001b[K\rremote: Counting objects:  28% (2/7)\u001b[K\rremote: Counting objects:  42% (3/7)\u001b[K\rremote: Counting objects:  57% (4/7)\u001b[K\rremote: Counting objects:  71% (5/7)\u001b[K\rremote: Counting objects:  85% (6/7)\u001b[K\rremote: Counting objects: 100% (7/7)\u001b[K\rremote: Counting objects: 100% (7/7), done.\u001b[K\n",
            "remote: Compressing objects:  25% (1/4)\u001b[K\rremote: Compressing objects:  50% (2/4)\u001b[K\rremote: Compressing objects:  75% (3/4)\u001b[K\rremote: Compressing objects: 100% (4/4)\u001b[K\rremote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 4 (delta 3), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects:  25% (1/4)   \rUnpacking objects:  50% (2/4)   \rUnpacking objects:  75% (3/4)   \rUnpacking objects: 100% (4/4)   \rUnpacking objects: 100% (4/4), done.\n",
            "From https://github.com/TeamDeLollis/RTransformerSapienza\n",
            "   8a600377..413a46c0  master     -> origin/master\n",
            "Updating 8a600377..413a46c0\n",
            "Fast-forward\n",
            " sentiment/experiment.py | 2 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " 1 file changed, 1 insertion(+), 1 deletion(-)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KtVeoJNvbFwv",
        "colab_type": "code",
        "outputId": "65a85b4d-6345-483d-d802-8ff79f5185fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd sentiment"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/RTransformerSapienza/sentiment\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1Y0CDE_3FgP",
        "colab_type": "code",
        "outputId": "e537a1f0-5433-480a-be48-7e904d1f7c64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mtest\u001b[0m/  \u001b[01;34mtrain\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZ2dGT3Ibn_M",
        "colab_type": "code",
        "outputId": "6cc77a95-babd-48d2-920b-79bb6f4195bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83
        }
      },
      "source": [
        "!python experiment.py --cuda"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/RTransformerSapienza/sentiment/data/\n",
            "pickle\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8728qERepUh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsqMaIs4NY58",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git add *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_cpa7LUvN1JI",
        "colab_type": "code",
        "outputId": "23e19945-ad31-49a5-8ab4-12d0fb9d0413",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!git commit -m \"ciao\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[master ffc2a508] ciao\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7NBNWpqUwVD",
        "colab_type": "code",
        "outputId": "16673219-2c14-4f75-f114-57e59543b6a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        }
      },
      "source": [
        "!git push"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Counting objects: 20, done.\n",
            "Delta compression using up to 2 threads.\n",
            "Compressing objects: 100% (20/20), done.\n",
            "Writing objects: 100% (20/20), 368.38 MiB | 11.08 MiB/s, done.\n",
            "Total 20 (delta 7), reused 0 (delta 0)\n",
            "remote: Resolving deltas: 100% (7/7), completed with 3 local objects.\u001b[K\n",
            "remote: error: GH001: Large files detected. You may want to try Git Large File Storage - https://git-lfs.github.com.\u001b[K\n",
            "remote: error: Trace: 1de78deccc0bc95d5469e1a7d8cc7572\u001b[K\n",
            "remote: error: See http://git.io/iEPt8g for more information.\u001b[K\n",
            "remote: error: File sentiment/output/m_d_128_h_8_t_LSTM_ksize_9_level_3_n_1_lr_0.001_dropout_0.25.pt is 233.59 MB; this exceeds GitHub's file size limit of 100.00 MB\u001b[K\n",
            "remote: error: File sentiment/output/m_d_128_h_8_t_LSTM_ksize_9_level_3_n_1_lr_0.001_dropout_0.25.pt is 225.37 MB; this exceeds GitHub's file size limit of 100.00 MB\u001b[K\n",
            "To https://github.com/TeamDeLollis/RTransformerSapienza\n",
            " ! [remote rejected]   master -> master (pre-receive hook declined)\n",
            "error: failed to push some refs to 'https://TeamDeLollis:diag1234!@github.com/TeamDeLollis/RTransformerSapienza'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDVgW83RRryV",
        "colab_type": "code",
        "outputId": "fb942805-8c9c-477d-ebd8-f3befedeeeef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "!git pull"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "remote: Enumerating objects: 41, done.\u001b[K\n",
            "remote: Counting objects:   2% (1/41)\u001b[K\rremote: Counting objects:   4% (2/41)\u001b[K\rremote: Counting objects:   7% (3/41)\u001b[K\rremote: Counting objects:   9% (4/41)\u001b[K\rremote: Counting objects:  12% (5/41)\u001b[K\rremote: Counting objects:  14% (6/41)\u001b[K\rremote: Counting objects:  17% (7/41)\u001b[K\rremote: Counting objects:  19% (8/41)\u001b[K\rremote: Counting objects:  21% (9/41)\u001b[K\rremote: Counting objects:  24% (10/41)\u001b[K\rremote: Counting objects:  26% (11/41)\u001b[K\rremote: Counting objects:  29% (12/41)\u001b[K\rremote: Counting objects:  31% (13/41)\u001b[K\rremote: Counting objects:  34% (14/41)\u001b[K\rremote: Counting objects:  36% (15/41)\u001b[K\rremote: Counting objects:  39% (16/41)\u001b[K\rremote: Counting objects:  41% (17/41)\u001b[K\rremote: Counting objects:  43% (18/41)\u001b[K\rremote: Counting objects:  46% (19/41)\u001b[K\rremote: Counting objects:  48% (20/41)\u001b[K\rremote: Counting objects:  51% (21/41)\u001b[K\rremote: Counting objects:  53% (22/41)\u001b[K\rremote: Counting objects:  56% (23/41)\u001b[K\rremote: Counting objects:  58% (24/41)\u001b[K\rremote: Counting objects:  60% (25/41)\u001b[K\rremote: Counting objects:  63% (26/41)\u001b[K\rremote: Counting objects:  65% (27/41)\u001b[K\rremote: Counting objects:  68% (28/41)\u001b[K\rremote: Counting objects:  70% (29/41)\u001b[K\rremote: Counting objects:  73% (30/41)\u001b[K\rremote: Counting objects:  75% (31/41)\u001b[K\rremote: Counting objects:  78% (32/41)\u001b[K\rremote: Counting objects:  80% (33/41)\u001b[K\rremote: Counting objects:  82% (34/41)\u001b[K\rremote: Counting objects:  85% (35/41)\u001b[K\rremote: Counting objects:  87% (36/41)\u001b[K\rremote: Counting objects:  90% (37/41)\u001b[K\rremote: Counting objects:  92% (38/41)\u001b[K\rremote: Counting objects:  95% (39/41)\u001b[K\rremote: Counting objects:  97% (40/41)\u001b[K\rremote: Counting objects: 100% (41/41)\u001b[K\rremote: Counting objects: 100% (41/41), done.\u001b[K\n",
            "remote: Compressing objects:   7% (1/14)\u001b[K\rremote: Compressing objects:  14% (2/14)\u001b[K\rremote: Compressing objects:  21% (3/14)\u001b[K\rremote: Compressing objects:  28% (4/14)\u001b[K\rremote: Compressing objects:  35% (5/14)\u001b[K\rremote: Compressing objects:  42% (6/14)\u001b[K\rremote: Compressing objects:  50% (7/14)\u001b[K\rremote: Compressing objects:  57% (8/14)\u001b[K\rremote: Compressing objects:  64% (9/14)\u001b[K\rremote: Compressing objects:  71% (10/14)\u001b[K\rremote: Compressing objects:  78% (11/14)\u001b[K\rremote: Compressing objects:  85% (12/14)\u001b[K\rremote: Compressing objects:  92% (13/14)\u001b[K\rremote: Compressing objects: 100% (14/14)\u001b[K\rremote: Compressing objects: 100% (14/14), done.\u001b[K\n",
            "remote: Total 32 (delta 21), reused 28 (delta 17), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (32/32), done.\n",
            "From https://github.com/TeamDeLollis/RTransformerSapienza\n",
            "   00ec67fc..1fdf5b19  master     -> origin/master\n",
            "Removing ner/data/corpus/corpus\n",
            "Removing ner/__pycache__/utils.cpython-37.pyc\n",
            "Removing ner/__pycache__/model.cpython-37.pyc\n",
            "hint: Waiting for your editor to close the file... error: unable to start editor 'editor'\n",
            "Not committing merge; use 'git commit' to complete the merge.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}